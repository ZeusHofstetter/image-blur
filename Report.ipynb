{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Automatized Picture Quality Assesment through Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the invention of digital photography the process of taking and processing holiday pictures has drastically changed. With analog photography the number of pictures per film role was limited to around 30, leading to only 100-200 pictures per holiday, and consequently each picture was taken with great care and precission.\n",
    "Now, the memory of a digital camera can hold many thousands of images and the quality of the pictures can be evaluated at a later point. This has lead to a steep increase of the number of pictures per holiday but also to a decrease in the average picture quality, as less care has to be taken during the photography process.\n",
    "\n",
    "Through this simultaneous increase in picture quantity together with a decrease in average picture quality the post-processing steps in the photography process have become much more important. For amateur photographs, such as us, this is illustrated through the Xmas-calendar problem. \n",
    "The Xmas-calendar problem typically manifests in the last weeks befor Christmas, when the thousands of holiday pictures of the last year have to be assesed. In a first step the pictures have to be sorted in usable and unusable images, where unusable images are mainly classified as being blurry, out of focuss or obscured by an unwanted object, such as the typical finger in front of the lense. In a second more demanding step the usable images have to be sorted according to photographic quality, in order to find to 12-20 best pictures.\n",
    "\n",
    "In this project we develop and test a machine learning (ML) method in order to automatize these two picture quality assesment tasks. In a first step we use the CERTH Image Blur Dataset [1] to develope and test the performance of different ML methods to classify blurred and out of focuss images. Next, the top XX performing ML methods are tested on a personal dataset of blurred and non-blurred pictures, to determine the transferability of the chosen approach. If the chosen ML approach is indeed transferable, we will extend the CERTH Image Blur Dataset [1] with the personal dataset of blurred and non-blurred pictures, as well as a personal data set of obstructed images. We will then train and test the ML methods on this extended data-set to correctly classify the pictures as usable or unusable. \n",
    "\n",
    "In an extention to this work, or if we finish the first part soon enoughf, we propose to extend the ML approach, either by retraining the first ML classifieror by training a second ML classifier, to also sort the usable images based on photography quality. \n",
    "\n",
    "[1] E. Mavridaki, V. Mezaris, \"No-Reference blur assessment in natural images using Fourier transform and spatial pyramids\", Proc. IEEE International Conference on Image Processing (ICIP 2014), Paris, France, October 2014. http://mklab.iti.gr/project/imageblur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of ML approach based on the CERTH Image Blur Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline for classification accuracy\n",
    "\n",
    "First we establish a baseline to compare our more advanced models agains. \n",
    "The testing and training of the baseline can be found in the file transferVGG16.ipynb.\n",
    "The classification accuracy is calculated as:\n",
    "\n",
    "##### Prediction accuracy of Dummy Classifier\n",
    "Train: 0.588 <br>\n",
    "Test: 0.554\n",
    "\n",
    "##### Prediction accuracy of Random Forest Classifier\n",
    "Train: 0.999 <br>\n",
    "Test: 0.600\n",
    "\n",
    "##### Prediction accuracy for VGG16 with Dummy Classifier\n",
    "Train: 0.605 <br>\n",
    "Test: 0.543\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning based on VGG16 with logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation for different models and model parameters of the transfer learning based on VGG16 can be found in the file transferVGG16.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Prediction accuracy for chosen VGG16 model with Logistic Regression\n",
    "training score:  1.0 <br>\n",
    "test score:  0.727"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning based on other pre-trained models together with logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the testing with VGG16 it seems that extracting the output at the last pooling layer is the most promising.\n",
    "Now we are going to test the performance of some other pre-trained Neural Networks. The full script can be found in transfer_lerning_v2.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Prediction accuracy for VGG19 model with Logistic Regression\n",
    "training score:  1.0 <br>\n",
    "test score:  0.712\n",
    "\n",
    "##### Prediction accuracy for ResNet50 model with Logistic Regression\n",
    "training score:  1.0 <br>\n",
    "test score:  0.784\n",
    "\n",
    "##### Prediction accuracy for DenseNet121 model with Logistic Regression\n",
    "training score:  1.0 <br>\n",
    "test score:  0.714\n",
    "\n",
    "##### Prediction accuracy for Xception model with Logistic Regression\n",
    "training score:  1.0 <br>\n",
    "test score:  0.653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all the transfer learning models the ResNet50 has the highest test score. But even for the ResNet50 model the test score is still quite low. This might either be due to the poor performance of the Logistic Regression Classifier or due to the fact that most image recognition Neural Networks include some kind of convolutional blurring, which will probably negatively impact the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning based on XXX with decision trees or with gradient boosting or ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized blurred dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the personal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of the different ML approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
